{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "gk_D0EK3xW1c",
    "outputId": "15b1d8b4-0707-4b6a-ed81-dd59e42ef1f9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Input, Dense, GaussianNoise,Lambda,Dropout, Concatenate, Add\n",
    "from keras  import layers\n",
    "from keras.models import Model\n",
    "from keras import regularizers \n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.io as io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "M_xKwSEhxoE0",
    "outputId": "1cf1fd62-b949-4ea7-c8b2-ed8367262816"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "om_dpmqWxW1p"
   },
   "outputs": [],
   "source": [
    "M=16\n",
    "\n",
    "Tx=2\n",
    "Rx=2\n",
    "\n",
    "Tx_NN=256\n",
    "Rx_NN=2048\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rnG52zUvJi9L",
    "outputId": "98491760-49db-4d73-9a66-528587dc4270"
   },
   "outputs": [],
   "source": [
    "np.arange(0,20,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "qBs--jbFxW2L",
    "outputId": "1299bc06-4802-40ee-9cf9-d547177d539e"
   },
   "outputs": [],
   "source": [
    "#Build encoder\n",
    "\n",
    "M_input=Input(shape=(M,), name='M')\n",
    "V_input = Input(shape=(8,), name='V')\n",
    "Ch_input =Input(shape=(8,), name='CH')\n",
    "Sigma = Input(shape=(1,), name='SIGMA')\n",
    "U_input = Input(shape=(8,), name='U')\n",
    "\n",
    "Tx_input = keras.layers.Concatenate(axis=-1, name='sig2Tx')([M_input, V_input])\n",
    "\n",
    "layer = Dense(units =Tx_NN, activation='relu')(Tx_input)\n",
    "layer = Dense(units =Tx_NN, activation='relu')(layer)\n",
    "\n",
    "Tx_output = Dense(units =2*Tx, activation='linear')(layer)\n",
    "Tx_output =  Lambda(lambda x: x / K.sqrt(2*K.mean(K.square(x))), name='Power_Constrain')(Tx_output)\n",
    "\n",
    "to_mimo = keras.layers.Concatenate(axis=-1, name='sig2Channel')([Tx_output, Ch_input, Sigma])\n",
    "\n",
    "\n",
    "def mimo_channel(in_know):    \n",
    "    sig = in_know[:, 0:4]\n",
    "    ch = in_know[:, 4:12]\n",
    "    sigma = in_know[0, 12]\n",
    "    \n",
    "    sig_real = tf.reshape(sig[:, 0:2], (-1, 2,1))\n",
    "    sig_imag = tf.reshape(sig[:, 2:4], (-1, 2,1))\n",
    "    \n",
    "    ch_real = tf.reshape(ch[:, 0:4], (-1,2,2))\n",
    "    ch_imag = tf.reshape(ch[:, 4:8], (-1,2,2))\n",
    "    \n",
    "    rx_real = tf.matmul(ch_real, sig_real) - tf.matmul(ch_imag, sig_imag) \n",
    "    rx_imag = tf.matmul(ch_real, sig_imag) + tf.matmul(ch_imag, sig_real)\n",
    "    rx = tf.reshape(tf.concat([rx_real, rx_imag], axis=1), (-1, 4))\n",
    "    rx = rx + tf.random.normal(mean=0, stddev=sigma, shape=tf.shape(rx))\n",
    "    return rx\n",
    "Rx= Lambda(mimo_channel, name='Channel_Layer')(to_mimo)\n",
    "\n",
    "\n",
    "# Build Decoder\n",
    "\n",
    "Rx_input = keras.layers.Concatenate(axis=-1, name='sig2Rx')([Rx, U_input])\n",
    "layer = Dense(units=Rx_NN, activation='relu')(Rx_input)\n",
    "layer = Dense(units=Rx_NN, activation='relu')(layer)\n",
    "layer = Dense(units=Rx_NN, activation='relu')(layer)\n",
    "Rx_output = Dense(units=M, activation='softmax')(layer)\n",
    "\n",
    "auto_encoder = Model(inputs=[M_input, Ch_input, U_input,Sigma, V_input], outputs= Rx_output)\n",
    "\n",
    "opt = Adam(lr=0.001)\n",
    "auto_encoder.compile(optimizer=opt, loss='categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 768
    },
    "colab_type": "code",
    "id": "eiik1gJ37rHi",
    "outputId": "923d854d-1561-4874-ee4d-5a5bf09ff3d1"
   },
   "outputs": [],
   "source": [
    "M_input3=Input(shape=(M,), name='M')\n",
    "Ch_input3 =Input(shape=(8,), name='CH')\n",
    "Sigma3 = Input(shape=(1,), name='SIGMA')\n",
    "\n",
    "Tx_input3 = keras.layers.Concatenate(axis=-1, name='sig2Tx')([M_input3, Ch_input3])\n",
    "\n",
    "layer3 = Dense(units =Tx_NN, activation='relu')(Tx_input3)\n",
    "layer3 = Dense(units =Tx_NN, activation='relu')(layer3)\n",
    "\n",
    "Tx_output3 = Dense(units =2*Tx, activation='linear')(layer3)\n",
    "Tx_output3 =  Lambda(lambda x: x / K.sqrt(2*K.mean(K.square(x))), name='Power_Constrain')(Tx_output3)\n",
    "\n",
    "to_mimo3 = keras.layers.Concatenate(axis=-1, name='sig2Channel')([Tx_output3, Ch_input3, Sigma3])\n",
    "\n",
    "\n",
    "Rx3= Lambda(mimo_channel, name='Channel_Layer')(to_mimo3)\n",
    "\n",
    "\n",
    "# Build Decoder\n",
    "\n",
    "Rx_input3 = keras.layers.Concatenate(axis=-1, name='sig2Rx')([Rx3, Ch_input3])\n",
    "Rx_input3 = BatchNormalization()(Rx_input3)\n",
    "layer3 = Dense(units=Rx_NN, activation='relu')(Rx_input3)\n",
    "layer3 = BatchNormalization()(layer3)\n",
    "layer3 = Dense(units=Rx_NN, activation='relu')(layer3)\n",
    "layer3 = BatchNormalization()(layer3)\n",
    "layer3 = Dense(units=Rx_NN, activation='relu')(layer3)\n",
    "layer3 = BatchNormalization()(layer3)\n",
    "Rx_output3 = Dense(units=M, activation='softmax')(layer3)\n",
    "\n",
    "auto_encoder3 = Model(inputs=[M_input3, Ch_input3, Sigma3], outputs= Rx_output3)\n",
    "\n",
    "opt3 = Adam(lr=0.001)\n",
    "#configures the model for training\n",
    "auto_encoder3.compile(optimizer=opt3, loss='categorical_crossentropy')\n",
    "\n",
    "\n",
    "batch=6400 * 40\n",
    "\n",
    "train_messages = np.arange(M)\n",
    "train_messages = np.tile(train_messages, batch)\n",
    "train_labels = to_categorical(train_messages)\n",
    "\n",
    "channel = (np.random.normal(size=[batch * 16, 2, 2]) + 1j*np.random.normal(size=[batch * 16, 2, 2]))/np.sqrt(2)\n",
    "ch = np.reshape(channel, (-1, 4))\n",
    "ch = np.concatenate([ch.real, ch.imag], axis=-1)\n",
    "\n",
    "T_SNR = 15\n",
    "snr_linear = np.power(10, T_SNR/10)\n",
    "sigma_train = np.sqrt(0.5/snr_linear)\n",
    "sigma_train = sigma_train * np.ones((ch.shape[0],1))\n",
    "\n",
    "history = auto_encoder3.fit(x=[train_labels, ch,sigma_train], y=train_labels, batch_size=20480, verbose=1, epochs=15)\n",
    "\n",
    "# batch=6400 * 400\n",
    "\n",
    "# train_messages = np.arange(M)\n",
    "# train_messages = np.tile(train_messages, batch)\n",
    "# train_labels = to_categorical(train_messages)\n",
    "\n",
    "# channel = (np.random.normal(size=[batch * 16, 2, 2]) + 1j*np.random.normal(size=[batch * 16, 2, 2]))/np.sqrt(2)\n",
    "# ch = np.reshape(channel, (-1, 4))\n",
    "# ch = np.concatenate([ch.real, ch.imag], axis=-1)\n",
    "\n",
    "# T_SNR = 15\n",
    "# snr_linear = np.power(10, T_SNR/10)\n",
    "# sigma_train = np.sqrt(0.5/snr_linear)\n",
    "# sigma_train = sigma_train * np.ones((ch.shape[0],1))\n",
    "\n",
    "# history = auto_encoder3.fit(x=[train_labels, ch,sigma_train], y=train_labels, batch_size=20480, verbose=1, epochs=15)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i3RwsYTE0vYu"
   },
   "outputs": [],
   "source": [
    "auto_encoder3.save('path_to_my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u1knO1cA1Do7"
   },
   "outputs": [],
   "source": [
    "# new_model = keras.models.load_model('path_to_my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "th1dy_ovi00D"
   },
   "outputs": [],
   "source": [
    "# SNR_array = np.arange(0, 22)\n",
    "# SER3 = []\n",
    "# for snr in SNR_array:\n",
    "#     snr_linear = np.power(10, snr/10)\n",
    "#     sigma_train = np.sqrt(0.5/snr_linear)\n",
    "\n",
    "#     batch=6400\n",
    "#     train_messages = np.arange(M)\n",
    "#     train_messages = np.tile(train_messages, batch)\n",
    "#     train_labels = to_categorical(train_messages)\n",
    "\n",
    "#     channel = (np.random.normal(size=[batch * 16, 2, 2]) + 1j*np.random.normal(size=[batch * 16, 2, 2]))/np.sqrt(2)\n",
    "#     ch = np.reshape(channel, (-1, 4))\n",
    "#     ch = np.concatenate([ch.real, ch.imag], axis=-1)\n",
    "\n",
    "    \n",
    "#     sigma_train = sigma_train * np.ones((ch.shape[0],1))\n",
    "\n",
    "#     prob_distribution = auto_encoder3.predict(x=[train_labels, ch, sigma_train], batch_size=1024*10)\n",
    "   \n",
    "#     classification = np.argmax(prob_distribution, axis=1)\n",
    "#     correct = np.equal(classification , train_messages)\n",
    "#     ser = 1- np.mean(correct)\n",
    "#     SER3 = np.append(SER3, ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WInqVl_qkLIy"
   },
   "outputs": [],
   "source": [
    "SNR_array = np.arange(0, 25,5)\n",
    "SER3 = []\n",
    "for snr in SNR_array:\n",
    "    ser_flag = 0\n",
    "    for temp in np.arange(20):\n",
    "        ser = 0\n",
    "        snr_linear = np.power(10, snr/10)\n",
    "        sigma_train = np.sqrt(0.5/snr_linear)\n",
    "        frames = 150\n",
    "        batch=64000\n",
    "        train_messages = np.arange(M)\n",
    "        train_messages = np.tile(train_messages, batch)\n",
    "        train_labels = to_categorical(train_messages)\n",
    "\n",
    "        channel = (np.random.normal(size=[frames * 16, 2, 2]) + 1j*np.random.normal(size=[frames * 16, 2, 2]))/np.sqrt(2)\n",
    "        channel = np.tile(channel, (batch,1,1))\n",
    "        ch = np.reshape(channel, (-1, 4))\n",
    "        ch = np.concatenate([ch.real, ch.imag], axis=-1)\n",
    "\n",
    "        \n",
    "        sigma_train = sigma_train * np.ones((ch.shape[0],1))\n",
    "\n",
    "        prob_distribution = auto_encoder3.predict(x=[train_labels, ch, sigma_train], batch_size=1024*10)\n",
    "      \n",
    "        classification = np.argmax(prob_distribution, axis=1)\n",
    "        correct = np.equal(classification , train_messages)\n",
    "        ser = 1- np.mean(correct)\n",
    "        ser_flag = ser_flag + ser\n",
    "        \n",
    "    SER3 = np.append(SER3, ser_flag/20)\n",
    "    # print(SER3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "colab_type": "code",
    "id": "EKiGeFjK5_Jn",
    "outputId": "c957af8d-5992-4348-b35d-b5b0fc0d2f84"
   },
   "outputs": [],
   "source": [
    "print(SER3)\n",
    "plt.figure()\n",
    "SNR = np.arange(0, 22)\n",
    "\n",
    "base_line = np.array([0.51663, 0.47059, 0.42939 ,0.3782,  0.34221, 0.30084 ,0.26423, 0.22573 ,0.1949,\n",
    " 0.16623, 0.14124, 0.1161 , 0.09486 ,0.07995, 0.06518 ,0.05308, 0.04256, 0.03233,\n",
    " 0.02639 ,0.02132, 0.0185 , 0.01276])\n",
    "csitr, base = plt.semilogy(SNR_array, SER3, SNR, base_line)\n",
    "plt.grid(True)\n",
    "plt.legend([ csitr, base], ['simulation_with_csitr', 'Base_line'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "colab_type": "code",
    "id": "pygnGD6jtohB",
    "outputId": "117d47f4-7970-47d6-a61c-cc8ec1bd489a"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SNR_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-659db587303f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mcsitr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msemilogy\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mSNR_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSER3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSNR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_line\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSNR_baseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSVD_optimal_SER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mcsitr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ser_with_csitr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'QPSK'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Bits-and-power-allocation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SNR_array' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x648 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "SNR = np.arange(0, 22)\n",
    "\n",
    "base_line = np.array([0.51663, 0.47059, 0.42939 ,0.3782,  0.34221, 0.30084 ,0.26423, 0.22573 ,0.1949,\n",
    " 0.16623, 0.14124, 0.1161 , 0.09486 ,0.07995, 0.06518 ,0.05308, 0.04256, 0.03233,\n",
    " 0.02639 ,0.02132, 0.0185 , 0.01276])\n",
    "\n",
    "SNR_baseline = np.arange(0,27,2)\n",
    "\n",
    "SVD_optimal_SER = io.loadmat('SVD_optimal_SER.mat')['SER']\n",
    "print(SVD_optimal_SER)\n",
    "\n",
    "\n",
    "\n",
    "csitr, base, base2 = plt.semilogy( SNR_array, SER3, SNR, base_line,SNR_baseline, SVD_optimal_SER[0,:])\n",
    "plt.grid(True)\n",
    "plt.legend([ csitr, base, base2], ['ser_with_csitr', 'QPSK','Bits-and-power-allocation'])\n",
    "plt.xlabel('SNR')\n",
    "plt.ylabel('SER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ICtOMizFAroT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": " SVD_AlternativeLearning_copy3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
